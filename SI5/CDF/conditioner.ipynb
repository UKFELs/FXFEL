{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Puffin Beam Conditioner\n",
    "\n",
    "This notebook will guide you through the process of converting an electron beam distribution from an external source (e.g. an external accelerator code) into Puffin. The distribution is re-conditioned to obey the expected noise characteristics relevant to the start-up process in SASE in a FEL.\n",
    "\n",
    "If the beam has been generated in a \"one-to-one\" simulation (meaning, the simulation was performed with real electrons), then this MAY not need to be done.\n",
    "\n",
    "This noteboook has been converted from the original Python script by Piotr T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time:  2016-09-05 11:59:50\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tables\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print 'Current time: ',now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "file_name_in = 'test_1kSI.si5'\n",
    "\n",
    "file_name_base  = (file_name_in.split('.')[0]).strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 6)\n",
      "Peak density =  6.28084339162e+19 (Number of electrons per meter cubed)\n",
      "Mean beam energy (Lorentz factor)=  100.350652402\n",
      "FEL parameter rho =  0.0177221314955\n",
      "RMS undulator parameter =  1\n",
      "Wiggler period =  0.04 (m)\n",
      "Resonant wavelength =  3.97209466956e-06 (m)\n",
      "Gain length =  0.179616810942 (m)\n",
      "Cooperation length =  1.78363744327e-05 (m)\n"
     ]
    }
   ],
   "source": [
    "e_ch=1.602e-19\n",
    "Pi=3.1415\n",
    "k_u=157.075\n",
    "a_u=1\n",
    "c=3.0e+8\n",
    "m=9.11e-31\n",
    "e_0=8.854E-12 \n",
    "\n",
    "\n",
    "\n",
    "# Open file, assign particles\n",
    "\n",
    "f=tables.open_file(file_name_in,'r')\n",
    "Particles=f.root.Particles.read()\n",
    "mA_X = Particles[:,0]\n",
    "mA_Y = Particles[:,2]    \n",
    "mA_Z = Particles[:,4]\n",
    "mA_PX = Particles[:,1]\n",
    "mA_PY = Particles[:,3]  \n",
    "mA_PZ = Particles[:,5]\n",
    "mA_WGHT = Particles[:,6]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "# FEL characteristics\n",
    "\n",
    "\n",
    "# Get peak spatial density of input beam\n",
    "\n",
    "xyz = np.vstack([mA_X,mA_Y,mA_Z]).T\n",
    "size_x=max(mA_X)-min(mA_X)\n",
    "size_y=max(mA_Y)-min(mA_Y)\n",
    "size_z=max(mA_Z)-min(mA_Z)\n",
    "binnumber=6\n",
    "cube_volume=(size_x*size_y*size_z)/float(binnumber**3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "H, edges = np.histogramdd(xyz, bins = (binnumber,binnumber,binnumber),normed=False,weights=mA_WGHT.flat)\n",
    "print H.shape\n",
    "\n",
    "n_p=float(np.amax(H))/cube_volume\n",
    "\n",
    "\n",
    "# Derive FEL parameters from the input beam\n",
    "\n",
    "p_tot=np.sqrt((mA_PX[:]**2)+(mA_PY[:]**2)+(mA_PZ[:]**2))\n",
    "gamma=(np.sqrt(1+(p_tot/(m*c))**2))\n",
    "gamma_0=np.mean(gamma)\n",
    "omega_p=np.sqrt((e_ch*e_ch*n_p)/(e_0*m))\n",
    "rho=(1/gamma_0)*(((a_u*omega_p)/(4*c*k_u))**(2.0/3.0))\n",
    "lambda_u=(2*Pi)/k_u\n",
    "lambda_r=(lambda_u/(2*gamma_0**2))*(1+a_u**2)\n",
    "Lg = lambda_u / (4*Pi*rho)\n",
    "Lc=lambda_r/(4*Pi*rho)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print 'Peak density = ', n_p, '(Number of electrons per meter cubed)'\n",
    "print 'Mean beam energy (Lorentz factor)= ', gamma_0\n",
    "print 'FEL parameter rho = ', rho\n",
    "print 'RMS undulator parameter = ', a_u\n",
    "print 'Wiggler period = ', lambda_u, '(m)'\n",
    "print 'Resonant wavelength = ', lambda_r, '(m)'\n",
    "print 'Gain length = ', Lg, '(m)'\n",
    "print 'Cooperation length = ', Lc, '(m)'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binnumber X,Y,Z =  10 10 10\n",
      "Charge in beam =  4.518441e-09\n",
      "Number of source macroparticles:  1000\n",
      "(1000, 2) (1000, 2)\n",
      "(10,) (11,)\n"
     ]
    }
   ],
   "source": [
    "# number_of_bins=int((size_z/Lc)*1.10)\n",
    "number_of_bins=10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "binnumber_Z = number_of_bins  \n",
    "binnumber_X = 10  # Lawrence changed this part\n",
    "binnumber_Y = 10  # Lawrence changed this part\n",
    "\n",
    "print'Binnumber X,Y,Z = ',binnumber_X,binnumber_Y,binnumber_Z\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xyzW = np.vstack((mA_X.flat,mA_Y.flat,mA_Z.flat,mA_WGHT.flat)).T\n",
    "\n",
    "xyzW = xyzW[xyzW[:,2].argsort()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mB_X=xyzW[:,0].flat\n",
    "mB_Y=xyzW[:,1].flat\n",
    "mB_Z=xyzW[:,2].flat\n",
    "mB_WGHT=xyzW[:,3].flat\n",
    "\n",
    "\n",
    "# Set the multiplier of desired particle number\n",
    "# The higher the number the more time it will take\n",
    "# Please not that if you set this too high the algorithm will still work\n",
    "# but at the end your particles will have smaller than one what means that \n",
    "# you have less than one electron per particle\n",
    "# Currently there is no safety mechanism to avoid this\n",
    "DensityFactor=1000\n",
    "\n",
    "\n",
    "#Calculate total charge\n",
    "TotalNumberOfElectrons=np.sum(mA_WGHT)\n",
    "print 'Charge in beam = ',TotalNumberOfElectrons*e_ch\n",
    "print 'Number of source macroparticles: ',len(mB_X)\n",
    "\n",
    "# Set desired particle number per slice - best to set the number that will give \n",
    "# an integer when total number of source particles will be divided over it\n",
    "# Otherwise your particles will be cut at the end\n",
    "# Very low number can give weird results\n",
    "\n",
    " \n",
    "m_X=mB_X[:]\n",
    "m_Y=mB_Y[:]\n",
    "m_Z=mB_Z[:]\n",
    "m_WGHT=mB_WGHT[:]\n",
    "          \n",
    "m_Xm_Z=np.vstack((mA_X.flat,mA_Z.flat)).T\n",
    "m_Ym_Z=np.vstack((mA_Y.flat,mA_Z.flat)).T\n",
    "print np.shape(m_Xm_Z),np.shape(m_Ym_Z)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Hz, edges_Z = np.histogram(m_Z, bins = binnumber_Z,normed=False,weights=m_WGHT.flat)\n",
    "\n",
    "print np.shape(Hz),np.shape(edges_Z)\n",
    "\n",
    "\n",
    "#Hz, edges_Z = np.histogramdd(m_Z, bins = binnumber_Z,normed=False,weights=m_WGHT.flat)\n",
    "#Hy, edges_Y = np.histogramdd(m_Y, bins = binnumber_Y,normed=False,weights=m_WGHT.flat)\n",
    "#Hx, edges_X = np.histogramdd(m_X, bins = binnumber_X,normed=False,weights=m_WGHT.flat)\n",
    "\n",
    "\n",
    "#HxHz,edges_XZ = np.histogramdd(m_Xm_Z, bins = (binnumber_X,binnumber_Z),normed=False,weights=m_WGHT.flat)\n",
    "#HyHz,edges_YZ = np.histogramdd(m_Ym_Z, bins = (binnumber_Y,binnumber_Z),normed=False,weights=m_WGHT.flat)\n",
    "\n",
    "\n",
    "\n",
    "#data= np.vstack((m_X.ravel(),m_Z.ravel())).T\n",
    "#x, y = data.T\n",
    "#nbins=20\n",
    "#k = kde.gaussian_kde(data.T,weights=mB_WGHT[:])\n",
    "#xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "#zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "#plt.pcolormesh(xi, yi, zi.reshape(xi.shape))\n",
    "#plt.show()\n",
    "\n",
    "#XZarr=np.zeros(((len(edges_XZ[0])-1)*(len(edges_XZ[1])-1),3))\n",
    "#YZarr=np.zeros(((len(edges_YZ[0])-1)*(len(edges_YZ[1])-1),3))\n",
    "\n",
    "plt.scatter(mA_Z, mA_PZ)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(m_Z, bins = binnumber_Z,normed=False,weights=m_WGHT.flat)\n",
    "plt.show()\n",
    "\n",
    "dz = edges_Z[1] - edges_Z[0]\n",
    "pts_z = edges_Z + 0.5*dz\n",
    "pts_z = pts_z[0:-1]\n",
    "\n",
    "plt.plot(pts_z, Hz)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the raw input data and a histogram. We use this to get an interpolated function of the input. You can choose here which kind of interpolation you need. If your histogram (in other words, the current) is spiky, then you probably want to use the LSQ splines to smooth it out. Otherwise, if it seems smooth enough already, use the cubic. The preview should guide you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Interpolate density along Z-axis\n",
    "#x0_Z = np.linspace(np.min(m_Z),np.max(m_Z),binnumber_Z)\n",
    "#x0_Z = np.linspace(0.5*(edges_Z[0][0]+edges_Z[0][1]),0.5*(edges_Z[0][binnumber_Z]+edges_Z[0][binnumber_Z-1]),binnumber_Z)\n",
    "\n",
    "#y0_Z = Hz\n",
    "\n",
    "#z_hstgrm_length=0.5*(edges_Z[0][binnumber_Z]+edges_Z[0][binnumber_Z-1])-0.5*(edges_Z[0][0]+edges_Z[0][1])\n",
    "\n",
    "#t_knots_z=[min(x0_Z)+0.1*z_hstgrm_length,min(x0_Z)+0.25*z_hstgrm_length,np.mean(x0_Z),max(x0_Z)-0.25*z_hstgrm_length,max(x0_Z)-0.1*z_hstgrm_length]\n",
    "#t_knots_z=[edges_Z[0][0]+0.1*z_hstgrm_length,edges_Z[0][0]+0.25*z_hstgrm_length,(edges_Z[0][binnumber_Z]+edges_Z[0][0])*0.5,edges_Z[0][binnumber_Z]-0.25*z_hstgrm_length,edges_Z[0][binnumber_Z]-0.1*z_hstgrm_length]\n",
    "#t_knots_z=[edges_Z[0][0]+0.25*z_hstgrm_length,edges_Z[0][binnumber_Z]-0.25*z_hstgrm_length]\n",
    "# f_Z = interpolate.LSQUnivariateSpline(x0_Z, y0_Z,t_knots_z,ext=0)\n",
    "\n",
    "\n",
    "#pts_z = pts_z.append(pts_z[-1] + dz)\n",
    "#pts_z = array([pts_z[0]-dz]).append(pts_z)\n",
    "\n",
    "#Hz = array([0]).append(Hz)\n",
    "#Hz = Hz.append(0)\n",
    "\n",
    "\n",
    "zstt = pts_z[0]-dz\n",
    "zedt = pts_z[-1]+dz\n",
    "\n",
    "\n",
    "pts_z = np.append([zstt], pts_z)\n",
    "pts_z = np.append(pts_z, [zedt])\n",
    "\n",
    "Hz = np.append([0], Hz)\n",
    "Hz = np.append(Hz, [0])\n",
    "\n",
    "\n",
    "f_Z = interpolate.interp1d(pts_z, Hz, 'cubic')\n",
    "\n",
    "\n",
    "#f_Z = interpolate.UnivariateSpline(x0_Z, y0_Z,k=5)\n",
    "#print 0.5*(edges_Z[0][binnumber_Z]+edges_Z[0][binnumber_Z-1]),0.5*(edges_Z[0][0]+edges_Z[0][1])\n",
    "#print np.min(m_Z),np.max(mA_Z)\n",
    "znew = np.linspace(pts_z[0], pts_z[-1], 200)\n",
    "zds = f_Z(znew)\n",
    "\n",
    "#print np.shape(zds), np.shape(znew)\n",
    "\n",
    "plt.plot(pts_z, Hz, 'or', znew, zds, '-')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
